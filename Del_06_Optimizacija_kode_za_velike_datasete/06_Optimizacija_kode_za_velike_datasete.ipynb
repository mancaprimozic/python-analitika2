{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Del 6: Optimizacija kode za velike datasete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pripravimo datasete:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xJf data/data_del_06.tar.xz -C ./data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viri:\n",
    "- [A Beginner’s Guide to Optimizing Pandas Code for Speed](https://engineering.upside.com/a-beginners-guide-to-optimizing-pandas-code-for-speed-c09ef2c6a4d6)\n",
    "- [How to Optimize your Pandas Code](https://kanoki.org/2019/01/09/how-to-optimize-your-pandas-code/)\n",
    "- [Optimization tricks](http://ehneilsen.net/notebook/pandasExamples/pandas_examples.html#orgheadline36)\n",
    "- [Enhancing performance](https://pandas.pydata.org/pandas-docs/stable/user_guide/enhancingperf.html)\n",
    "- [Fast, Flexible, Easy and Intuitive: How to Speed Up Your Pandas Projects](https://realpython.com/fast-flexible-pandas/)\n",
    "- [Optimizing Code Performance On Large Datasets](https://app.dataquest.io/course/improving-code-performance)\n",
    "- [4 Unique Methods to Optimize your Python Code for Data Science](https://www.analyticsvidhya.com/blog/2019/09/4-methods-optimize-python-code-data-science/)\n",
    "- [High-Performance Pandas: eval() and query()](https://jakevdp.github.io/PythonDataScienceHandbook/03.12-performance-eval-and-query.html#pandas.eval()-for-Efficient-Operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Code optimization, in simple terms, means reducing the number of operations to execute any task while producing the correct results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU Bound Programs\n",
    "\n",
    "### Bounds vs Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"I/O bounds\" src=\"images/CPU+and+I_O+bounds.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer optimizacije"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a basic Haversine distance formula\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    MILES = 3959\n",
    "    lat1, lon1, lat2, lon2 = map(np.deg2rad, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1 \n",
    "    dlon = lon2 - lon1 \n",
    "    a = np.sin(dlat/2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    total_miles = MILES * c\n",
    "    return total_miles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/new_york_hotels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crude looping over DataFrame rows using indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to manually loop over all rows and return a series of distances\n",
    "def haversine_looping(df):\n",
    "    distance_list = []\n",
    "    for i in range(0, len(df)):\n",
    "        d = haversine(40.671, -73.985,   )\n",
    "        \n",
    "        \n",
    "        \n",
    "    return distance_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Run the haversine looping function\n",
    "df['distance'] = haversine_looping(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looping with iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Haversine applied on rows via iteration\n",
    "haversine_series = []\n",
    "\n",
    "\n",
    "\n",
    "df['distance'] = haversine_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looping with apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "# Timing apply on the Haversine function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization with Pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "# Vectorized implementation of Haversine applied on Pandas series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Vectorization with NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Vectorized implementation of Haversine applied on NumPy arrays\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This brings us to a few basic conclusions on optimizing Pandas code:\n",
    "1. Avoid loops; they’re slow and, in most common use cases, unnecessary.\n",
    "2. If you must loop, use apply(), not iteration functions.\n",
    "3. Vectorization is usually better than scalar operations. Most common operations in Pandas can be vectorized.\n",
    "4. Vector operations on NumPy arrays are more efficient than on native Pandas series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I/O Bound Programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O Bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/report_assembly.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/report_assembly_bidir.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I/O bound tasks are tasks where:\n",
    "- Our program is reading from an input (like a CSV file).\n",
    "- Our program is writing to an output (like a text file).\n",
    "- Our program is waiting for another program to execute something (like a SQL query).\n",
    "- Our program is waiting for another server to execute something (like an API request).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling an I/O bound task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT DISTINCT teamID \n",
    "FROM Teams \n",
    "INNER JOIN TeamsFranchises ON Teams.franchID == TeamsFranchises.franchID \n",
    "WHERE TeamsFranchises.active = 'Y';\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(\"data/lahman2015.sqlite\")\n",
    "\n",
    "cur = conn.cursor()\n",
    "teams = [row[0] for row in cur.execute(query).fetchall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import sqlite3\n",
    "\n",
    "query = \"SELECT SUM(HR) FROM Batting WHERE teamId=?\"\n",
    "conn = sqlite3.connect(\"data/lahman2015.sqlite\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "def calculate_runs(teams):\n",
    "    home_runs = []\n",
    "    for team in teams:\n",
    "        runs = cur.execute(query, [team]).fetchall()\n",
    "        runs = runs[0][0]\n",
    "        home_runs.append(runs)\n",
    "    return home_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "home_runs = calculate_runs(teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_string = \"home_runs = calculate_runs(teams)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cProfile.run(profile_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blocking Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "51    0.120    0.002    0.120    0.002 {method 'execute' of 'sqlite3.Cursor' objects}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "conn = sqlite3.connect(':memory:')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Create an in memory database.\n",
    "memory = sqlite3.connect(':memory:')\n",
    "\n",
    "# Connect to our disk database.\n",
    "disk = sqlite3.connect('data/lahman2015.sqlite')\n",
    "\n",
    "# Create a query that will read the contents of the disk database \n",
    "# into another database.\n",
    "dump = ''.join(line for line in disk.iterdump())\n",
    "\n",
    "# Run the query to copy the database from disk into memory.\n",
    "memory.executescript(dump)\n",
    "\n",
    "cur = memory.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import sqlite3\n",
    "\n",
    "query = \"SELECT SUM(HR) FROM Batting WHERE teamId=?\"\n",
    "\n",
    "def calculate_runs(teams):\n",
    "    home_runs = []\n",
    "    for team in teams:\n",
    "        runs = cur.execute(query, [team]).fetchall()\n",
    "        runs = runs[0][0]\n",
    "        home_runs.append(runs)\n",
    "    return home_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_string = \"home_runs = calculate_runs(teams)\"\n",
    "cProfile.run(profile_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/single_threaded.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " What if, instead, we could run several queries at once? It might look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/multi_threaded.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the Python 3 [threading library](https://docs.python.org/3/library/threading.html) to implement threading in our programs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(team):\n",
    "    print(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(team):\n",
    "    print(team)\n",
    "    \n",
    "\n",
    "for n, team in enumerate(teams):\n",
    "    thread = threading.Thread(target=task, args=(team,))\n",
    "    thread.start()\n",
    "    print('Started task', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thread Blocking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/three_threads.svg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "\n",
    "def task(team):\n",
    "    time.sleep(3)\n",
    "    print(team)\n",
    "    \n",
    "for n, team in enumerate(teams):\n",
    "    thread = threading.Thread(target=task, args=(team,))\n",
    "    thread.start()\n",
    "    print('Started task', n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "t1 = threading.Thread(target=task, args=(team,))\n",
    "t2 = threading.Thread(target=task, args=(team,))\n",
    "t3 = threading.Thread(target=task, args=(team,))\n",
    "\n",
    "# Start the first three threads\n",
    "t1.start()\n",
    "t2.start()\n",
    "t3.start()\n",
    "\n",
    "t1.join() # Wait until t1 finishes.\n",
    "t2.join() # Wait until t2 finishes.  If it already finished, then keep going.\n",
    "t3.join() # Wait until t3 finishes.  If it already finished, then keep going.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/Screenshot from 2019-06-29 16-40-25.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task(team):\n",
    "    print(team)\n",
    "\n",
    "for i in range(11):\n",
    "    team_names = teams[i*5: (i+1) * 5]\n",
    "    threads = []\n",
    "    for team in team_names:\n",
    "        thread = threading.Thread(target=task, args=(team,))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    print(\"Finished batch {}\".format(i)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to be aware of accessing shared resources when you're working with threads. Some examples of shared resources are:\n",
    "- The system stdout.\n",
    "- SQL databases.\n",
    "- APIs.\n",
    "- Objects in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "def task(team):\n",
    "    lock.acquire()\n",
    "    # This code cannot be executed until a thread acquires the lock.\n",
    "    print(team)\n",
    "    lock.release()\n",
    "\n",
    "t1 = threading.Thread(target=task, args=(team,))\n",
    "t2 = threading.Thread(target=task, args=(team,))\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time\n",
    "import sys\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "def task(team):\n",
    "    lock.acquire()\n",
    "    print(team)\n",
    "    sys.stdout.flush()\n",
    "    lock.release()\n",
    "    \n",
    "for i in range(11):\n",
    "    team_names = teams[i*5: (i+1) * 5]\n",
    "    threads = []\n",
    "    for team in team_names:\n",
    "        thread = threading.Thread(target=task, args=(team,))\n",
    "        thread.start()\n",
    "        threads.append(thread)\n",
    "    for thread in threads:\n",
    "        thread.join()\n",
    "    print(\"Finished batch {}\".format(i))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thread Safety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, these operations are not thread safe:\n",
    "- Modifying data in memory.\n",
    "- Writing to a file.\n",
    "- Adding data to a database.\n",
    "- Modifying data via API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "import sqlite3\n",
    "import threading\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT DISTINCT teamID from Teams inner join TeamsFranchises on Teams.franchID == TeamsFranchises.franchID where TeamsFranchises.active = 'Y';\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"data/lahman2015.sqlite\", check_same_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n",
    "teams = [row[0] for row in cur.execute(query).fetchall()]\n",
    "\n",
    "query = \"SELECT SUM(HR) FROM Batting WHERE teamId=?\"\n",
    "lock = threading.Lock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_runs(team):\n",
    "    cur = conn.cursor()\n",
    "    runs = cur.execute(query, [team]).fetchall()\n",
    "    runs = runs[0][0]\n",
    "    lock.acquire()\n",
    "    print(team, ':', runs)\n",
    "    sys.stdout.flush()\n",
    "    lock.release()\n",
    "    return runs\n",
    "\n",
    "\n",
    "threads = []\n",
    "\n",
    "for team in teams:\n",
    "    thread = threading.Thread(target=calculate_runs, args=(team,))\n",
    "    thread.start()\n",
    "    threads.append(thread)\n",
    "    \n",
    "for thread in threads:\n",
    "    thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Python Code with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Looping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select columns and rows efficiently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/school.csv')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['City'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the top cities in a list\n",
    "top_cities = ['Brooklyn','Bronx','Manhattan','Jamaica','Long Island City']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.City.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/school.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salba praksa\n",
    "%%timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.City.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uporaba biult-in funkciji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining on indexes is faster than joining on columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct some sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000\n",
    "\n",
    "i1 = np.arange(n)\n",
    "np.random.shuffle(i1)\n",
    "df1 = pd.DataFrame({'i': i1,\n",
    "                    'j': np.random.randint(1,1000,n),\n",
    "                    'k': np.random.randint(1,1000,n)})\n",
    "\n",
    "i2 = np.arange(n)\n",
    "np.random.shuffle(i1)\n",
    "df2 = pd.DataFrame({'i': i2,\n",
    "                    'm': np.random.randint(1,1000,n),\n",
    "                    'n': np.random.randint(1,1000,n)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.set_index('i')\n",
    "df2 = df2.set_index('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRIMER: Pohitritev pandas kode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vir: \n",
    "- [Fast, Flexible, Easy and Intuitive: How to Speed Up Your Pandas Projects](https://realpython.com/fast-flexible-pandas/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naloga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Priprava podatkov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/demand_profile.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_time'] = pd.to_datetime(df['date_time'])\n",
    "df['date_time'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(df, column_name):\n",
    "    return pd.to_datetime(df[column_name])\n",
    "\n",
    "df = pd.read_csv('data/demand_profile.csv')\n",
    "df_coverted = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 10\n",
    "df_coverted['date_time'] = convert(df, 'date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_with_format(df, column_name):\n",
    "    return pd.to_datetime(df[column_name], format='%d/%m/%y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 10\n",
    "df_coverted['date_time'] = convert_with_format(df, 'date_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "859/18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coverted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coverted.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Simple Looping Over Pandas Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table class=\"table table-hover\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Tariff Type</th>\n",
    "<th>Cents per kWh</th>\n",
    "<th>Time Range</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>Peak</td>\n",
    "<td>28</td>\n",
    "<td>17:00 to 24:00</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Shoulder</td>\n",
    "<td>20</td>\n",
    "<td>7:00 to 17:00</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Off-Peak</td>\n",
    "<td>12</td>\n",
    "<td>0:00 to 7:00</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_coverted.copy()\n",
    "df_test['cost_cents'] = df['energy_kwh'] * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tariff(kwh, hour):\n",
    "    \"\"\"Calculates cost of electricity for given hour.\"\"\"    \n",
    "    if 0 <= hour < 7:\n",
    "        rate = 12\n",
    "    elif 7 <= hour < 17:\n",
    "        rate = 20\n",
    "    elif 17 <= hour < 24:\n",
    "        rate = 28\n",
    "    else:\n",
    "        raise ValueError(f'Invalid hour: {hour}')\n",
    "    return rate * kwh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Don't do this!\n",
    "def apply_tariff_loop(df):\n",
    "    \"\"\"Calculate costs in loop.  Modifies `df` inplace.\"\"\"\n",
    "    energy_cost_list = []\n",
    "    for i in range(len(df)):\n",
    "        # Get electricity used and hour of day\n",
    "        \n",
    "    df['cost_cents'] = energy_cost_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 10\n",
    "apply_tariff_loop(df_coverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Looping with .itertuples() and .iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df[:5].iterrows():\n",
    "    print(index)\n",
    "    print(row)\n",
    "    print('energy_kwh' ,row['energy_kwh'])\n",
    "    print('-------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tariff_iterrows(df):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 10\n",
    "apply_tariff_iterrows(df_coverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Pandas’ .apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tariff_withapply(df):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 10\n",
    "apply_tariff_withapply(df_coverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Selecting Data With .isin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coverted = df.copy()\n",
    "df_coverted['date_time'] = convert_with_format(df, 'date_time')\n",
    "df_coverted.set_index('date_time', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coverted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tariff_isin(df):\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 10\n",
    "apply_tariff_isin(df_coverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Pandas’ pd.cut() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coverted = df.copy()\n",
    "df_coverted['date_time'] = convert_with_format(df, 'date_time')\n",
    "df_coverted.set_index('date_time', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **[pandas.cut](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.cut.html)**\n",
    "- `pandas.cut(x, bins, right=True, labels=None, retbins=False, precision=3, include_lowest=False, duplicates='raise')`\n",
    "- Bin values into discrete intervals.\n",
    "- Use cut when you need to segment and sort data values into bins. This function is also useful for going from a continuous variable to a categorical variable. For example, cut could convert ages to groups of age ranges. Supports binning into an equal number of bins, or a pre-specified array of bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tariff_cut(df):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 10\n",
    "apply_tariff_cut(df_coverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coverted = df.copy()\n",
    "df_coverted['date_time'] = convert_with_format(df, 'date_time')\n",
    "df_coverted.set_index('date_time', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **[numpy.digitize](https://docs.scipy.org/doc/numpy/reference/generated/numpy.digitize.html)**\n",
    "- `numpy.digitize(x, bins, right=False)`\n",
    "- Return the indices of the bins to which each value in input array belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tariff_digitize(df):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 3 -n 10\n",
    "apply_tariff_digitize(df_coverted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevent Reprocessing with HDFStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[What is HDF5](https://portal.hdfgroup.org/display/knowledge/What+is+HDF5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coverted.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create storage object with filename `processed_data`\n",
    "data_store = pd.HDFStore('data/OUT_processed_data.h5')\n",
    "\n",
    "# Put DataFrame into the object setting the key as 'preprocessed_df'\n",
    "data_store['preprocessed_df'] = df_coverted\n",
    "data_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store = pd.HDFStore('data/OUT_processed_data.h5')\n",
    "\n",
    "# Retrieve data using key\n",
    "preprocessed_df = data_store['preprocessed_df']\n",
    "data_store.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Povzetek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>\n",
    "<p>Try to use <a href=\"https://realpython.com/numpy-array-programming/#what-is-vectorization\">vectorized operations</a> where possible rather than approaching problems with the <code>for x in df...</code> mentality. If your code is home to a lot of for-loops, it might be better suited to working with native Python data structures, because Pandas otherwise comes with a lot of overhead.</p>\n",
    "</li>\n",
    "<li>\n",
    "<p>If you have more complex operations where vectorization is simply impossible or too difficult to work out efficiently, use the <code>.apply()</code> method.</p>\n",
    "</li>\n",
    "<li>\n",
    "<p>If you do have to loop over your array (which does happen), use <code>.iterrows()</code> or <code>.itertuples()</code> to improve speed and syntax.</p>\n",
    "</li>\n",
    "<li>\n",
    "<p>Pandas has a lot of optionality, and there are almost always several ways to get from A to B. Be mindful of this, compare how different routes perform, and choose the one that works best in the context of your project.</p>\n",
    "</li>\n",
    "<li>\n",
    "<p>Once you’ve got a data cleaning script built, avoid reprocessing by storing your intermediate results with HDFStore.</p>\n",
    "</li>\n",
    "<li>\n",
    "<p>Integrating NumPy into Pandas operations can often improve speed and simplify syntax.</p>\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drugi nasveti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  [Numba](https://numba.pydata.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba translates Python functions to optimized machine code at runtime using the industry-standard LLVM compiler library. Numba-compiled numerical algorithms in Python can approach the speeds of C or FORTRAN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pandas.eval() for Efficient Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Dokumentacija](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.eval.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[High-Performance Pandas: eval() and query()](https://jakevdp.github.io/PythonDataScienceHandbook/03.12-performance-eval-and-query.html#pandas.eval()-for-Efficient-Operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As of version 0.13 (released January 2014), Pandas includes some experimental tools that allow you to directly access C-speed operations without costly allocation of intermediate arrays. These are the eval() and query() functions, which rely on the Numexpr package."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
